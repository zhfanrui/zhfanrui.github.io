---
layout:   post
title:    "手写 Python 爬虫"
subtitle: "医学文献处理引擎"
date:     2016-04-27 16:46:10
author:   "Stephen"
header-img: "img/post-bg.jpg"
catalog: true
tag:
    - Python
    - Web Scraper
---

## 前情提要

在蹭 [李建伟]() 老师的 [操作系统]() 课的时候，有一天他突然问起谁会 HTML ，我当然义不容辞的举手了。所以才有了一切的一切。

他带的研究生正在做一个关于医学的 APP 的课题，需要数据处理，而整个项目的难点在于： **所有的文献是从不同的网站上保存下来的，所以文件的格式不尽相同**。

## 解决方案一

一开始我认为，正则表达式是可以解决这个问题的。但经过多次调试发现次法并不好用。所以我咨询了正在教我们课的老师 Dr. Giovanni ，然后他的答复让我真正的省去了很多的麻烦。

## 解决方案二

Dr. Giovanni 让我使用一个 Python 库，名为 [BeautifulSoup]() 。这个库十分强大，可直接分析 HTML 语句，并且查找也十分方便。

有了工具，剩下的当然是算法了。这种问题当然还是使用一个 DFS 来做。我的第一个念头就是 **如果一个 DIV 下面有 5 个以上的 P 标签，那么基本可以判断为所求段落**。

这就是 BETA 的版本，相当的简单。

一开始这个办法还是挺好使的，但是后来应对他给我的将近 100 个文件的时候，效果并不是很理想，但还是说的过去，我就先把 BETA 版给了老师。

## 解决方案三

结果当然是不理想的。

后来老师又找我，让我再改改。其实并没什么难的，我早就想到了，其实加几个特判就好了。

但其实还是挺费时间的，我大概加到凌晨两点多，加了没几个，主要还是第一个调试的时间长，后来几个就简单了。

这次运行下来，效果还可以。命名为 VERSON 1.0 。

## 改进

说到改进还是有的。
 - VERSON 1.0 的版本，增加了对图片的支持，即图片直接生成网页。
 - 包括以后可能会支持 PDF 格式的文件。‘

## 问题

其实这个算法还是相当有问题的：
 - 如果抓取网页的标签嵌套有问题的话，解析器会发生问题，然后只抓取前半部分。
 - BETA 版的算法还是不太好用。
希望大家如果有好的算法，邮箱告诉我：zhfanrui#outlook.com

